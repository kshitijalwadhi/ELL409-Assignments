{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "np.random.seed(42)\n",
    "import math\n",
    "import random\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readData(filename):\n",
    "    dataset = []\n",
    "    with open(filename) as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "        for row in csv_reader:\n",
    "            dataset.append([float(row[0]),float(row[1])])\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotData(dataset):\n",
    "    dataset = np.array(dataset)\n",
    "    X = dataset[:,0]\n",
    "    y = dataset[:,1]\n",
    "    plt.scatter(X,y,color=\"b\",marker='o',s=20)\n",
    "    plt.ylabel('t')\n",
    "    plt.xlabel('x')\n",
    "    plt.title('Gaussian Noise Dataset')\n",
    "    plt.show\n",
    "    plt.savefig('Gaussian Noise Dataset.png',dpi=1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation_split(dataset):\n",
    "    dataset_split = list()\n",
    "    dataset_copy = list(dataset)\n",
    "    fold_size = int(len(dataset) / N_FOLDS)\n",
    "    for i in range(N_FOLDS):\n",
    "        fold = list()\n",
    "        while len(fold) < fold_size:\n",
    "            index = random.randrange(len(dataset_copy))\n",
    "            fold.append(dataset_copy.pop(index))\n",
    "        dataset_split.append(fold)\n",
    "    return dataset_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# highest power is m here\n",
    "def makeDesignMat(x,m):\n",
    "    return np.vander(x,m+1,increasing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunkarr(arr,n):\n",
    "    return [arr[i:i + n] for i in range(0, len(arr), n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_error(train_err_list,test_err_list):\n",
    "    xa = np.linspace(1,len(train_err_list),len(train_err_list),dtype=int)\n",
    "    plt.figure()\n",
    "    plt.plot(xa,train_err_list,color=\"g\")\n",
    "    plt.plot(xa,test_err_list,color=\"r\")\n",
    "    plt.xlabel('Iterations')\n",
    "    plt.ylabel('Error')\n",
    "    plt.title('Error vs Iterations')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def descent(trainX,y,testX,testY,lambd = 0.0, err_function = \"mse\" ):\n",
    "    #m = len(trainX)\n",
    "    w = np.random.rand(MAX_POWER+1)\n",
    "    y = np.array(y)\n",
    "    X = makeDesignMat(trainX,MAX_POWER)\n",
    "    Xchunks = chunkarr(X,BATCH_SIZE)\n",
    "    ychunks = chunkarr(y,BATCH_SIZE)\n",
    "    train_err_list = []\n",
    "    test_err_list = []\n",
    "    for i in tqdm(range(NUM_ITER)):\n",
    "        for chunk in range(len(Xchunks)):\n",
    "            Xcon = Xchunks[chunk]\n",
    "            ycon = ychunks[chunk]\n",
    "            pred = np.dot(Xcon,w)\n",
    "            test_err_list.append(testError(testX,testY,w))\n",
    "            if err_function == \"mse\":\n",
    "                err = 0.5 * (np.sum(np.square(pred-ycon)) + lambd*np.sum(np.square(w)))/len(ycon)\n",
    "                grad = (np.dot(Xcon.T,(pred-ycon)) + lambd*w)/len(ycon)\n",
    "            if err_function == \"mae\":\n",
    "                err = np.sum(np.abs(pred-ycon))\n",
    "                parity = np.sign(pred - ycon)\n",
    "                parity = parity.reshape((len(ycon),1))\n",
    "                grad = np.sum(np.multiply(parity,Xcon).T,axis=1)/len(ycon)\n",
    "            if err_function == \"huber\":\n",
    "                e = 0.1\n",
    "                temp = pred-ycon\n",
    "                err = np.sum(np.where(np.abs(temp)<=e,0.5*temp*temp,(e*np.abs(temp) - 0.5*e*e)))\n",
    "                err += lambd*np.sum(np.square(w))\n",
    "                err /= len(ycon)\n",
    "                grad = np.zeros((MAX_POWER+1,))\n",
    "                for i in range(len(ycon)):\n",
    "                    if np.abs(temp[i]<=e):\n",
    "                        grad += temp[i]*Xcon[i,:]\n",
    "                    else:\n",
    "                        grad += e*np.sign(temp[i])*Xcon[i,:]\n",
    "                grad+=2*lambd*w\n",
    "                w = np.squeeze(w)\n",
    "                grad /=len(ycon)\n",
    "                grad = np.squeeze(grad)\n",
    "            w = w - LEARNING_RATE * grad\n",
    "            train_err_list.append(err)\n",
    "    plot_error(train_err_list,test_err_list)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_reg(trainX,trainY,testX,testY,w):\n",
    "    def aux(X_line,w):\n",
    "        temp = 0\n",
    "        for i in range(len(w)):\n",
    "            temp += np.power(X_line,i) * w[i]\n",
    "        return temp\n",
    "    jointX = np.concatenate((trainX,testX))\n",
    "    plt.scatter(trainX,trainY,color='b',marker ='o',s=15)\n",
    "    plt.scatter(testX,testY,color=\"m\",marker='o',s=30)\n",
    "    x_line = np.linspace(min(jointX),max(jointX),100)\n",
    "    y_pred = aux(x_line,w)\n",
    "    plt.plot(x_line,y_pred, color='g')\n",
    "    plt.xlabel('X')\n",
    "    plt.ylabel('y')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testError(testX, testY,w):\n",
    "    testX = makeDesignMat(testX,MAX_POWER)\n",
    "    pred = np.dot(testX,w)\n",
    "    if ERROR == \"mse\":\n",
    "        err = 0.5 * (np.sum(np.square(pred-testY)))/len(testY)\n",
    "    elif ERROR == \"mae\":\n",
    "        err = np.sum(np.abs(pred-testY)) / len(testY)\n",
    "    elif ERROR == \"huber\":\n",
    "        e = 0.1\n",
    "        temp = pred-testY\n",
    "        err = np.sum(np.where(np.abs(temp)<=e,0.5*temp*temp,(e*np.abs(temp) - 0.5*e*e))) / len(testY)\n",
    "    return err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dataset):\n",
    "    folds = cross_validation_split(dataset)\n",
    "    err_list = []\n",
    "    for fold in folds:\n",
    "        trainDS = list(folds)\n",
    "        trainDS.remove(fold)\n",
    "        trainDS = np.array(trainDS)\n",
    "        trainX = []\n",
    "        trainY = []\n",
    "        for i in range(len(trainDS)):\n",
    "            trainX.extend(trainDS[i][:,0])\n",
    "            trainY.extend(trainDS[i][:,1])\n",
    "        testDS = np.array(fold)\n",
    "        testX = testDS[:,0]\n",
    "        testY = testDS[:,1]\n",
    "        w = descent(trainX,trainY,testX,testY,REGULARIZATION_LAMBDA,ERROR)\n",
    "        plot_reg(trainX,trainY,testX,testY,w)\n",
    "        err = testError(testX,testY,w)\n",
    "        err_list.append(err)\n",
    "    avg_error = np.mean(err_list)\n",
    "    print(err_list)\n",
    "    return avg_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_moorepenrose(dataset):\n",
    "    folds = cross_validation_split(dataset)\n",
    "    err_list = []\n",
    "    for fold in folds:\n",
    "        trainDS = list(folds)\n",
    "        trainDS.remove(fold)\n",
    "        trainDS = np.array(trainDS)\n",
    "        trainX = []\n",
    "        trainY = []\n",
    "        for i in range(len(trainDS)):\n",
    "            trainX.extend(trainDS[i][:,0])\n",
    "            trainY.extend(trainDS[i][:,1])\n",
    "        testDS = np.array(fold)\n",
    "        testX = testDS[:,0]\n",
    "        testY = testDS[:,1]\n",
    "        X = makeDesignMat(trainX,MAX_POWER)\n",
    "        #w = np.dot(np.linalg.inv(np.dot(X.transpose(),X)),np.dot(X.transpose(),trainY))\n",
    "        w = np.dot(np.linalg.inv(np.dot(X.transpose(),X) + REGULARIZATION_LAMBDA * np.identity(MAX_POWER+1) ),np.dot(X.transpose(),trainY))\n",
    "        plot_reg(trainX,trainY,testX,testY,w)\n",
    "        err = testError(testX,testY,w)\n",
    "        err_list.append(err)\n",
    "    avg_error = np.mean(err_list)\n",
    "    print(w)\n",
    "    print(err_list)\n",
    "    return avg_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
